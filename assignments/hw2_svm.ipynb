{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aX3fNdxFnlH"
   },
   "source": [
    "# Homework 2 - SVM Classification\n",
    "\n",
    "## Problem 1 - EMNIST Letters Classification\n",
    "*This problem is based on the MNIST Exercises from Chapter 2 of Applied Machine Learning by David Forsyth (2019).*\n",
    "\n",
    "This problem is a continuation of homework 1 on Naive Bayes and Nearest Neighbors, continuing to use\n",
    "[EMNIST [1]](https://www.nist.gov/itl/products-and-services/emnist-dataset).\n",
    "\n",
    "1. (Same as step 1 from HW1) Load in the dataset (both training and test sets) so that each sample (e.g. image) is one row.  Each row should be of lenght 784 (each image is $28 \\times 28$, so if you view each pixel as a feature you would have $28 \\times 28$ features for each image.  \n",
    "\n",
    "2. Threshold the data so that any pixel under some cutoff (you can look at the data and determine what seems to be a reasonable cutoff) is a 0 and all values greater than or equal to the cutoff is a 1.  This isn't strictly necessary, but with an SVM it does give better results (you can try it yourself both with and without thresholding to verify)\n",
    "\n",
    "3. Using sklearn's SGDClassifier, build and evaluate a linear SVM model trained with Stochastic Gradient Descent with the $L2$-penalty and hinge loss. Use `partial_fit` and compute the accuracy on a held-out validation set after each epoch.  Plot these validation set accuracies.  How well does this do in comparison to the other methods from the previous assignment (or whatever ones you finished in that assignment)?\n",
    "\n",
    "\n",
    "[1] Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n",
    "\n",
    "\n",
    "<br><br>\n",
    "## Problem 2 - Forest Fire Classification\n",
    "UCI's Machine Learning Repository cotains a [dataset of measurements in Algeria for classifying whether or not a given sample is an instance of a forest fire ](https://archive.ics.uci.edu/ml/datasets/Algerian+Forest+Fires+Dataset++).  I've done some slight preprocessing of the dataset to make it a [version that is a little easier to work with](https://drive.google.com/file/d/1VK6PFUAgjlM1uTzoyhnSE1jWqgd3myFW/view?usp=sharing) (primarily fixing a formatting bug in the csv and combining the two regions into one simpler file).\n",
    "\n",
    "1. Read in the data and split your data into training, testing sets.  The data is still a little messy (there's some extra spaces at the starts and ends of columns), so you will want to make sure that you clean that up prior to splitting the data.  Before splitting, it's always good to understand your data and whether the classes are balanced.  When classes are unbalanced, it's often best to use stratified sampling (there is an option for this in `train_test_split`) which makes sure that the relative class frequencies are preserved in the split datasets.\n",
    "\n",
    "2. Using sklearn's SGDClassifier, build and train an SVM model (use hinge loss and L2-penalty) to predict whether or not a given sample is a forest fire. By using [`partial_fit`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.partial_fit), you can train a model with mini-batch stochastic gradient descent by passing a randomly sample of the data (say by sampling 32 or 64 data points) to `partial fit` each time.  Every so often (maybe every 10 or 20 times you call sample), evaluate your model on both the validation set and the training set and save the accuracies in separate arrays/lists.  Given you are using partial_fit, I'd recommend just splitting training into train and validation (but you are welcome to try to use cross-validation as well).  Plot both the training and validation accuracies.\n",
    "\n",
    "3. Experiment with a variety of values of regularization parameter (`alpha` parameter) between 1e-8 and 1e-1 and initial learning rate (`eta0` parameter) between 1e-8 and 1e-1. (I recommend using the `'invscaling'` learning rate schedule, but you are welcome to experiment with that as well).  What values to you find work best (and what caused you to determine that)?   (Note -- this is called \"hyperparameter tuning/optimization\")\n",
    "\n",
    "4. For whatever choices of hyperparameters you determined to be best, retrain your model on the full training set (so both train and validation combined).  Then predict on the test set and compute the accuracy of the predictions.  Display the results with a confusion matrix.  How does it do compare to baseline accuracy for this problem?\n",
    "\n",
    "<br><br>\n",
    "## Problem 3 - Incorporating New Features\n",
    "A linear SVM defines a decision boundary that is a hyper plane (meaning in 2D the decision boundary is a straight line).  We can make a linear SVM have the effect of a non-linear decision boundary by feature transformation, adding features based on the original features so that the classes can be separated by a hyperplane in that higher dimensional space.\n",
    "\n",
    "We'll look at one (artificial) example of this.  Suppose we make some data with the following (there are two classes that are clearly reasonably separable, but not by a straight line in this feature space).\n",
    "\n",
    "```\n",
    "from sklearn.datasets import make_circles\n",
    "pts, labels = make_circles(n_samples = 500, noise = 0.06)\n",
    "plt.scatter(pts[:,0], pts[:,1], c=labels)\n",
    "plt.show()\n",
    "```\n",
    " \n",
    "There are 500 points, each with two features (we'll call them $x_1$ and $x_2$ for a given sample $\\mathbf{x}$).  So, we could go all the way up to a feature space of size 5 by adding all of the higher order terms of degree two for these features (aka, $x_1^2$, $x_1 x_2$, and $x_2^2$).  Recall that the formula for a circle centered at the origin is $x^2 + y^2 = r^2$.  So, in a feature space based on just $x_1^2$ and $x_2^2$, the classes should be reasonably separable by a linear decision boundary.\n",
    "\n",
    "To show this:\n",
    "\n",
    "1. Start by creating a new 2D array containing the features $x_1^2$ and $x_2^2$ (note -- usually we might keep the lower order terms, but they aren't necessary for this example and having a 2D feature space makes it much easier to plot). \n",
    "\n",
    "2. Break your newly transformed data into training and test sets using `train_test_split`.  Train a linear SVM (hinge loss, L2 penalty term) on this newly transformed data (the training set).  It should do reasonably well with the defaults, but you are free to experiment with hyperparameter optimization if you want.\n",
    "\n",
    "3. Use sklearn's [`DecisionBoundaryDisplay.from_estimator`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html#sklearn.inspection.DecisionBoundaryDisplay.from_estimator) to illustrate the decision boundary and the data points (this is the `.scatter(...)` part in their example) to visually confirm that they are reasonably separated by the linear decision boundary in the transformed space.\n",
    "\n",
    "4. Compute the accuracy on the test set.\n",
    "\n",
    "Note -- the process we went through works, but it doesn't scale well.  Instead, there's a well known idea called the \"kernel trick\" which is more efficient but allows us to accomplish the same thing without explicitly adding all of those features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQoVQM-VFOzX"
   },
   "outputs": [],
   "source": [
    "!pip install emnist\n",
    "\n",
    "# If you are on colab this is needed to update sklearn to a newer version\n",
    "!pip uninstall scikit-learn -y\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItYbJAWUEcLI"
   },
   "outputs": [],
   "source": [
    "# Problem 2 - Example of how to access data from google drive\n",
    "'''\n",
    "Note, to use this you need to:\n",
    "1. upload the forest-fires-classification.csv file to your google drive\n",
    "2. update this to wherever forest-fires-classification.csv is on your google drive\n",
    "   (e.g. on mine it's in CIS378/hw2/forest-firest-classification.csv)\n",
    "'''\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "ffdata = pd.read_csv('/content/gdrive/MyDrive/CIS378/hw2/forest-fires-classification.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
